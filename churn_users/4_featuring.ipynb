{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ОПИСАНИЕ ЗАДАЧИ\n",
    "\n",
    "Данные:\n",
    "- чековые данные (transactions.parquet, для чтения через pandas дополнительно нужно установить библиотеку pyarrow)\n",
    "- справочник товаров (materials.csv)\n",
    "- справочник магазинов (plants.csv)\n",
    "- справочник клиентов (clients.csv)\n",
    "Более подробное описание данных дано в файле Data Description.\n",
    "\n",
    "Цель: \n",
    "1) проанализировать данные и определить оптимальную методологию определения отточных клиентов\n",
    "2) разработать модель вероятности оттока клиентов по выбранной вами методологии\n",
    "3) дать интерпретацию разработанной модели, ответить на вопросы: какие признаки наиболее влияют на отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ЧАСТЬ 4. FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gc\n",
    "from statistics import mode\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полезные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_vars(vars_to_del=['tmp', 'tmp2', 'tmp3' 'result']):\n",
    "    for var in vars_to_del:\n",
    "        if var in globals():\n",
    "            del globals()[str(var)]\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_to_int(df, cols):   \n",
    "    for col in cols:\n",
    "        c_min = df[col].min()\n",
    "        c_max = df[col].max()\n",
    "        if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "            df[col] = df[col].astype(np.int8)\n",
    "        elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "            df[col] = df[col].astype(np.int16)\n",
    "        elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "            df[col] = df[col].astype(np.int32)\n",
    "        elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "            df[col] = df[col].astype(np.int64)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = str(Path().absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.read_pickle(workdir+'/data/full.pkl')\n",
    "data = pd.read_pickle(workdir+'/data/target.pkl')\n",
    "clients = pd.read_pickle(workdir+'/data/clients.pkl')\n",
    "materials = pd.read_pickle(workdir+'/data/materials.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clnum = 1000\n",
    "# full = full[full.client_id<clnum]\n",
    "# data = data[data.client_id<clnum]\n",
    "# clients = clients[clients.client_id<clnum]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32094659 entries, 0 to 32094658\n",
      "Data columns (total 18 columns):\n",
      "chq_date            datetime64[ns]\n",
      "chq_position        int32\n",
      "sales_count         float16\n",
      "sales_sum           float32\n",
      "is_promo            bool\n",
      "client_id           int32\n",
      "material            int32\n",
      "plant               int16\n",
      "chq_id              int32\n",
      "price               float32\n",
      "hier_level_1        int8\n",
      "hier_level_2        int8\n",
      "hier_level_3        int16\n",
      "hier_level_4        int16\n",
      "vendor              int16\n",
      "is_private_label    bool\n",
      "is_alco             bool\n",
      "plant_type          int8\n",
      "dtypes: bool(3), datetime64[ns](1), float16(1), float32(2), int16(4), int32(4), int8(3)\n",
      "memory usage: 1.7 GB\n"
     ]
    }
   ],
   "source": [
    "full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36598170 entries, 0 to 36598169\n",
      "Data columns (total 7 columns):\n",
      "chq_date           datetime64[ns]\n",
      "client_id          int64\n",
      "chq_count_today    float64\n",
      "is_active          int32\n",
      "sum_today          float32\n",
      "is_high_active     int64\n",
      "is_churn           float64\n",
      "dtypes: datetime64[ns](1), float32(1), float64(2), int32(1), int64(2)\n",
      "memory usage: 1.6 GB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 99995 entries, 0 to 99994\n",
      "Data columns (total 4 columns):\n",
      "gender       99995 non-null int8\n",
      "birthyear    99995 non-null int32\n",
      "client_id    99995 non-null int32\n",
      "city         99995 non-null int8\n",
      "dtypes: int32(2), int8(2)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "clients.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 105609 entries, 0 to 105608\n",
      "Data columns (total 8 columns):\n",
      "hier_level_1        105609 non-null int8\n",
      "hier_level_2        105609 non-null int8\n",
      "hier_level_3        105609 non-null int16\n",
      "hier_level_4        105609 non-null int16\n",
      "vendor              105609 non-null int16\n",
      "is_private_label    105609 non-null bool\n",
      "is_alco             105609 non-null bool\n",
      "material            105609 non-null int32\n",
      "dtypes: bool(2), int16(3), int32(1), int8(2)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "materials.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_active'] = data['is_active'].astype(np.int8)\n",
    "data['is_high_active'] = data['is_high_active'].astype(np.int8)\n",
    "data['is_churn'] = data['is_churn'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engeneering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Примечание: часть изначально задуманных признаков были закомментированы, чтобы уменьшить их количество и увеличить скорость дальнейших вычислений._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Группа готовых признаков:\n",
    "* chq_date - день наблюдений\n",
    "* client_id\t- id клиента\n",
    "* chq_count_today - количество чеков в день наблюдений\n",
    "* sum_today\t- потраченная сумма в день наблюдений\n",
    "* is_active\t- признак активности в день наблюдений\n",
    "* is_high_active - признак высокой активности в день наблюдений\n",
    "* is_churn - целевая переменная оттока \n",
    "\n",
    "Группа дополнительных признаков, которые будут созданы:\n",
    "* номер текущей недели\n",
    "* агрегации активности клиента по периодам сегодня, на прошлой неделе, за 31 прошлых дней:\n",
    "    * доля товаров, купленных со скидкой за период\n",
    "    * (min, max, mean, sum) по количеству чеков за период\n",
    "    * (min, max, mean, sum) по потраченной сумме за период\n",
    "    * id магазина с максимальным количеством чеков клиента за период\n",
    "    * тип магазина с максимальным количеством чеков клиента за период\n",
    "    * id магазина с максимальной потраченной суммой за период\n",
    "    * тип магазина с максимальной потраченной суммой за период\n",
    "    * доля товаров, купленных со скидкой за период\n",
    "    * доля товаров в чеках за период по группам общих продаж: топовая, высокая, обычная, низкая\n",
    "    * количество товаров в чеках за период по группам общей частоты продаж: топовая, высокая, обычная, низкая (исключая возвратные транзакции)\n",
    "    * доля покупок за период самого популярного товара клиента по общей сумме его покупок\n",
    "    * доля покупок за период самого популярного товара клиента по общему количеству появлений в его чеках (исключая возвратные транзакции)\n",
    "    * доля купленных товаров за период в типе 1 категории 1\n",
    "    * доля суммы покупок за период в типе 1 категории 1\n",
    "    * доля товаров в чеках за период по группам общих продаж в категории 2: топовая, высокая, обычная, низкая\n",
    "    * доля товаров в чеках за период по группам общей частоты продаж в категории 2: топовая, высокая, обычная, низкая\n",
    "    * доля покупок клиента за период самого популярного типа в категории 2 по общей сумме покупок\n",
    "    * доля покупок клиента за период самого популярного типа в категории 2 по общему количеству появлений в его чеках \n",
    "    * доля товаров в чеках за период по группам общих продаж в категории 3: топовая, высокая, обычная, низкая\n",
    "    * доля товаров в чеках за период по группам общей частоты продаж в категории 3: топовая, высокая, обычная, низкая\n",
    "    * доля покупок клиента за период самого популярного типа в категории 3 по общей сумме его покупок\n",
    "    * доля покупок клиента за период самого популярного типа в категории 3 по общему количеству появлений в его чеках \n",
    "    * доля товаров в чеках за период по группам общих продаж в категории 4: топовая, высокая, обычная, низкая\n",
    "    * доля товаров в чеках за период по группам общей частоты продаж в категории 4: топовая, высокая, обычная, низкая\n",
    "    * доля покупок клиента за период самого популярного типа в категории 4 по общей сумме его покупок\n",
    "    * доля покупок клиента за период самого популярного типа в категории 4 по общему количеству появлений в его чеках \n",
    "    * доля товаров в чеках за период по группам общих продаж среди производителей: топовая, высокая, обычная, низкая\n",
    "    * доля товаров в чеках за период по группам общей частоты продаж среди производителей: топовая, высокая, обычная, низкая\n",
    "    * доля покупок за период самого популярного производителя клиента по общей сумме его покупок\n",
    "    * доля покупок за период самого популярного производителя клиента по общему количеству появлений в его чеках \n",
    "    * доля возвратных транзакций за период\n",
    "    * сумма возвратных транзакций за период\n",
    "    * доля покупок в категории is_private по сумме за период\n",
    "    * доля покупок в категории is_private по количеству за период\n",
    "    * доля покупок в категории is_alco по сумме за период\n",
    "    * доля покупок в категории is_alco по количеству за период\n",
    "    * доля товаров is_promo за период"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный датасет по товарам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расширим датасет material группировками:\n",
    "\n",
    "    type1_in_cat1 - принадлежность товара типу 0 в категории 1\n",
    "    \n",
    "    is_sales_sum_top - принадлежность к группе top-товары по общей сумме продаж\n",
    "    is_sales_sum_hgh - принадлежность к группе high-товары по общей сумме продаж\n",
    "    is_sales_sum_med - принадлежность к группе med-товары по общей сумме продаж\n",
    "    is_sales_cnt_top - принадлежность к группе top-товары по количеству появлений в чеках\n",
    "    is_sales_cnt_high - принадлежность к группе high-товары по количеству появлений в чеках\n",
    "    is_sales_cnt_med - принадлежность к группе med-товары по количеству появлений в чеках\n",
    "    \n",
    "    is_sales_sum_cat2_top - принадлежность к группе top-товары в категории 2 по общей сумме продаж\n",
    "    is_sales_sum_cat2_hgh - принадлежность к группе high-товары в категории 2 по общей сумме продаж\n",
    "    is_sales_sum_cat2_med - принадлежность к группе med-товары в категории 2 по общей сумме продаж\n",
    "    is_sales_cnt_cat2_top - принадлежность к группе top-товары в категории 2 по количеству появлений в чеках\n",
    "    is_sales_cnt_cat2_hgh - принадлежность к группе high-товары в категории 2 по количеству появлений в чеках\n",
    "    is_sales_cnt_cat2_med - принадлежность к группе med-товары в категории 2 по количеству появлений в чеках\n",
    "     \n",
    "    is_sales_sum_cat3_top - принадлежность к группе top-товары в категории 3 по общей сумме продаж\n",
    "    is_sales_sum_cat3_hgh - принадлежность к группе high-товары в категории 3 по общей сумме продаж\n",
    "    is_sales_sum_cat3_med - принадлежность к группе med-товары в категории 3 по общей сумме продаж\n",
    "    is_sales_cnt_cat3_top - принадлежность к группе top-товары в категории 3 по количеству появлений в чеках\n",
    "    is_sales_cnt_cat3_hgh - принадлежность к группе high-товары в категории 3 по количеству появлений в чеках\n",
    "    is_sales_cnt_cat3_med - принадлежность к группе med-товары в категории 3 по количеству появлений в чеках\n",
    "    \n",
    "    is_sales_sum_cat4_top - принадлежность к группе top-товары в категории 4 по общей сумме продаж\n",
    "    is_sales_sum_cat4_hgh - принадлежность к группе high-товары в категории 4 по общей сумме продаж\n",
    "    is_sales_sum_cat4_med - принадлежность к группе med-товары в категории 4 по общей сумме продаж\n",
    "    is_sales_cnt_cat4_top - принадлежность к группе top-товары в категории 4 по количеству появлений в чеках\n",
    "    is_sales_cnt_cat4_hgh - принадлежность к группе high-товары в категории 4 по количеству появлений в чеках\n",
    "    is_sales_cnt_cat4_med - принадлежность к группе med-товары в категории 4 по количеству появлений в чеках\n",
    "   \n",
    "    is_sales_sum_vndr_top - принадлежность к группе top-товары среди производителей по общей сумме продаж\n",
    "    is_sales_sum_vndr_hgh - принадлежность к группе high-товары среди производителей по общей сумме продаж\n",
    "    is_sales_sum_vndr_med - принадлежность к группе med-товары среди производителей по общей сумме продаж\n",
    "    is_sales_cnt_vndr_top - принадлежность к группе top-товары среди производителей по количеству появлений в чеках\n",
    "    is_sales_cnt_vndr_hgh - принадлежность к группе high-товары среди производителей по количеству появлений в чеках\n",
    "    is_sales_cnt_vndr_med - принадлежность к группе med-товары среди производителей по количеству появлений в чеках"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заранее удалим \"лишний\" товар 10721"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "materials = materials[materials.material!=10721]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### type1_in_cat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "materials.rename(columns={'hier_level_1':'is_type1_in_cat1'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### is_sales_sum_..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['material', 'hier_level_2', 'hier_level_3', 'hier_level_4', 'vendor']\n",
    "suffixes = ['', '_cat2', '_cat3', '_cat4', '_vndr'] \n",
    "for suffix, col in zip(suffixes, cols):\n",
    "    del_vars()\n",
    "    tmp = full[[col, 'sales_sum']]\n",
    "    result = tmp.groupby([col])['sales_sum'].sum().reset_index().sort_values(by='sales_sum', ascending=False)\n",
    "    result['percentile'] = None\n",
    "    total_sales = result.sales_sum.sum()\n",
    "    percentile = total_sales/10\n",
    "\n",
    "    curr_percentile = 0\n",
    "    i = 1\n",
    "    for index, row in result.iterrows():\n",
    "        curr_percentile = curr_percentile + row['sales_sum']\n",
    "        if curr_percentile >= percentile:\n",
    "            i = i + 1\n",
    "            curr_percentile = 0\n",
    "        result.at[index, 'percentile'] = i\n",
    "    result[f'is_sales_sum{suffix}_top'] = result['percentile'].apply(lambda x: 1 if x==1 else 0).astype(np.int8)\n",
    "    result[f'is_sales_sum{suffix}_hgh'] = result['percentile'].apply(lambda x: 1 if x in [2,3,4,5] else 0).astype(np.int8)\n",
    "#     result[f'is_sales_sum{suffix}_med'] = result['percentile'].apply(lambda x: 1 if x in [6,7,8,9] else 0).astype(np.int8)\n",
    "    materials = materials.merge(result.drop(columns=['sales_sum','percentile']), how='left', on=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### is_sales_cnt_..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['material', 'hier_level_2', 'hier_level_3', 'hier_level_4', 'vendor']\n",
    "suffixes = ['', '_cat2', '_cat3', '_cat4', '_vndr'] \n",
    "for suffix, col in zip(suffixes, cols):\n",
    "    del_vars()\n",
    "    # исключим из выборки возвратные транзакции\n",
    "    tmp = full[full.sales_sum>=0][[col, 'sales_sum']]\n",
    "\n",
    "    result = tmp.groupby([col])[col].count().rename('sales_cnt').reset_index().sort_values(by='sales_cnt', ascending=False)\n",
    "    result['percentile'] = None\n",
    "    total_sales = result.sales_cnt.sum()\n",
    "    percentile = total_sales/10\n",
    "\n",
    "    curr_percentile = 0\n",
    "    i = 1\n",
    "    for index, row in result.iterrows():\n",
    "        curr_percentile = curr_percentile + row['sales_cnt']\n",
    "        if curr_percentile >= percentile:\n",
    "            i = i + 1\n",
    "            curr_percentile = 0\n",
    "        result.at[index, 'percentile'] = i\n",
    "    result[f'is_sales_cnt{suffix}_top'] = result['percentile'].apply(lambda x: 1 if x==1 else 0).astype(np.int8)\n",
    "    result[f'is_sales_cnt{suffix}_hgh'] = result['percentile'].apply(lambda x: 1 if x in [2,3,4,5] else 0).astype(np.int8)\n",
    "#     result[f'is_sales_cnt{suffix}_med'] = result['percentile'].apply(lambda x: 1 if x in [6,7,8,9] else 0).astype(np.int8)\n",
    "    materials = materials.merge(result.drop(columns=['sales_cnt','percentile']), how='left', on=col)\n",
    "    materials = materials.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    " reduce_to_int(materials, materials.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### price_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = full.groupby('material')['price'].mean().rename('price_mean').reset_index()\n",
    "materials = materials.merge(result, how='left', on='material')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный датасет по клиентам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расширим датасет clients группировками:\n",
    "    \n",
    "    best_by_sum_plnt - самый популярный магазин по общей сумме покупок\n",
    "    best_by_cnt_plnt - самый популярный магазин по количеству покупок\n",
    "\n",
    "    best_by_sum_plid - самый популярный тип магазина по общей сумме покупок\n",
    "    best_by_cnt_plid - самый популярный тип магазина по количеству покупок\n",
    "    \n",
    "    best_by_sum_mtrl - самый популярный товар клиента по общей сумме его покупок\n",
    "    best_by_cnt_mtrl - самый популярный товар клиента по общему количеству появлений в его чеках (исключая возвратные транзакции)\n",
    "    \n",
    "    best_by_sum_cat2 - самый популярный тип в категории 2 у клиента по общей сумме его покупок\n",
    "    best_by_cnt_cat2 - самый популярный тип в категории 2 у клиента по общему количеству появлений в его чеках\n",
    "    \n",
    "    best_by_sum_cat3 - самый популярный тип в категории 3 у клиента по общей сумме его покупок\n",
    "    best_by_cnt_cat3 - самый популярный тип в категории 3 у клиента по общему количеству появлений в его чеках\n",
    "    \n",
    "    best_by_sum_cat4 - самый популярный тип в категории 4 у клиента по общей сумме его покупок\n",
    "    best_by_cnt_cat4 - самый популярный тип в категории 4 у клиента по общему количеству появлений в его чеках\n",
    "    \n",
    "    best_by_sum_vndr - самый популярный производитель у клиента по общей сумме его покупок\n",
    "    best_by_cnt_vndr - самый популярный производитель у клиента по общему количеству появлений в его чеках\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best_by_sum_..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['plant', 'plant_type', 'material', 'hier_level_2', 'hier_level_3', 'hier_level_4', 'vendor']\n",
    "suffixes = ['_plnt', '_plid', '_mtrl', '_cat2', '_cat3', '_cat4', '_vndr'] \n",
    "for suffix, col in zip(suffixes, cols):\n",
    "    del_vars()\n",
    "    tmp = full[[col, 'client_id', 'sales_sum']]\n",
    "    tmp2 = tmp.groupby([col,'client_id'])['sales_sum'].sum()\n",
    "    result = tmp2.loc[tmp2.groupby(level=1).idxmax()].reset_index()\n",
    "    clients = clients.merge(result[[col, 'client_id']].rename(columns={col:f'best_by_sum{suffix}'}), \n",
    "                            how='left', \n",
    "                            on='client_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best_by_cnt_..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['plant', 'plant_type', 'material', 'hier_level_2', 'hier_level_3', 'hier_level_4', 'vendor']\n",
    "suffixes = ['_plnt', '_plid', '_mtrl', '_cat2', '_cat3', '_cat4', '_vndr'] \n",
    "for suffix, col in zip(suffixes, cols):\n",
    "    del_vars()\n",
    "    tmp = full[full.sales_sum>=0][[col, 'client_id', 'sales_sum']]\n",
    "    tmp2 = tmp.groupby([col,'client_id'])[col].count()\n",
    "    result = tmp2.loc[tmp2.groupby(level=1).idxmax()].rename('cnt').reset_index()\n",
    "    clients = clients.merge(result[[col, 'client_id']].rename(columns={col:f'best_by_cnt{suffix}'}), \n",
    "                            how='left', \n",
    "                            on='client_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Суммирование всех сгенерированных показателей по датам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['is_private_label'] = full['is_private_label'].astype(np.int8)\n",
    "full['is_alco'] = full['is_alco'].astype(np.int8)\n",
    "full['is_promo'] = full['is_promo'].astype(np.int8)\n",
    "\n",
    "full = full.merge(clients.drop(columns=['gender', 'birthyear', 'city']), how='left', on='client_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = full.merge(materials.drop(columns=['hier_level_2', \n",
    "                                          'hier_level_3',\n",
    "                                          'hier_level_4',\n",
    "                                          'vendor',\n",
    "                                          'is_private_label',\n",
    "                                          'is_alco']), how='left', on='material')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['is_best_by_sum_plnt'] = (full['best_by_sum_plnt'] == full['plant']).apply(lambda x: 1 if x==True else 0).astype(np.int8)\n",
    "full['is_best_by_sum_plid'] = (full['best_by_sum_plid'] == full['plant_type']).apply(lambda x: 1 if x==True else 0).astype(np.int8)\n",
    "full['is_best_by_sum_mtrl'] = (full['best_by_sum_mtrl'] == full['material']).apply(lambda x: 1 if x==True else 0).astype(np.int8)\n",
    "full['is_best_by_sum_cat2'] = (full['best_by_sum_cat2'] == full['hier_level_2']).apply(lambda x: 1 if x==True else 0).astype(np.int8)\n",
    "full['is_best_by_sum_cat3'] = (full['best_by_sum_cat3'] == full['hier_level_3']).apply(lambda x: 1 if x==True else 0).astype(np.int8)\n",
    "full['is_best_by_sum_cat4'] = (full['best_by_sum_cat4'] == full['hier_level_4']).apply(lambda x: 1 if x==True else 0).astype(np.int8)\n",
    "full['is_best_by_sum_vndr'] = (full['best_by_sum_vndr'] == full['vendor']).apply(lambda x: 1 if x==True else 0).astype(np.int8)\n",
    "full['is_best_by_cnt_plnt'] = (full['best_by_cnt_plnt'] == full['plant']).apply(lambda x: 1 if x==True else 0).astype(np.int8)\n",
    "full['is_best_by_cnt_plid'] = (full['best_by_cnt_plid'] == full['plant_type']).apply(lambda x: 1 if x==True else 0).astype(np.int8)\n",
    "full['is_best_by_cnt_mtrl'] = (full['best_by_cnt_mtrl'] == full['material']).apply(lambda x: 1 if x==True else 0).astype(np.int8)\n",
    "full['is_best_by_cnt_cat2'] = (full['best_by_cnt_cat2'] == full['hier_level_2']).apply(lambda x: 1 if x==True else 0).astype(np.int8)\n",
    "full['is_best_by_cnt_cat3'] = (full['best_by_cnt_cat3'] == full['hier_level_3']).apply(lambda x: 1 if x==True else 0).astype(np.int8)\n",
    "full['is_best_by_cnt_cat4'] = (full['best_by_cnt_cat4'] == full['hier_level_4']).apply(lambda x: 1 if x==True else 0).astype(np.int8)\n",
    "full['is_best_by_cnt_vndr'] = (full['best_by_cnt_vndr'] == full['vendor']).apply(lambda x: 1 if x==True else 0).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['is_price_discount'] = (full['price_mean'] - full['price']).apply(lambda x: 1 if x>0 else 0).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full = full.drop(columns=[\n",
    "                         'best_by_sum_plnt',\n",
    "                         'best_by_sum_plid',\n",
    "                         'best_by_sum_mtrl',\n",
    "                         'best_by_sum_cat2',\n",
    "                         'best_by_sum_cat3',\n",
    "                         'best_by_sum_cat4',\n",
    "                         'best_by_sum_vndr',\n",
    "                         'best_by_cnt_plnt',\n",
    "                         'best_by_cnt_plid',\n",
    "                         'best_by_cnt_mtrl',\n",
    "                         'best_by_cnt_cat2',\n",
    "                         'best_by_cnt_cat3',\n",
    "                         'best_by_cnt_cat4',\n",
    "                         'best_by_cnt_vndr',\n",
    "                         'price',\n",
    "                         'price_mean',\n",
    "                         'plant',\n",
    "                         'plant_type',\n",
    "                         'hier_level_1',\n",
    "                         'hier_level_2',\n",
    "                         'hier_level_3',\n",
    "                         'hier_level_4',\n",
    "                         'vendor',\n",
    "                         'material',\n",
    "                         'chq_position', \n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['transactions_count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = full.groupby(['client_id','chq_date']).agg({\n",
    "    'transactions_count':'count',\n",
    "    'is_promo':'sum',\n",
    "    'is_private_label':'sum',\n",
    "    'is_alco':'sum',\n",
    "    'is_type1_in_cat1':'sum',\n",
    "    'is_sales_sum_top':'sum',\n",
    "    'is_sales_sum_hgh':'sum',\n",
    "#     'is_sales_sum_med':'sum',\n",
    "    'is_sales_sum_cat2_top':'sum',\n",
    "    'is_sales_sum_cat2_hgh':'sum',\n",
    "#     'is_sales_sum_cat2_med':'sum',\n",
    "    'is_sales_sum_cat3_top':'sum',\n",
    "    'is_sales_sum_cat3_hgh':'sum',\n",
    "#     'is_sales_sum_cat3_med':'sum',\n",
    "    'is_sales_sum_cat4_top':'sum',\n",
    "    'is_sales_sum_cat4_hgh':'sum',\n",
    "#     'is_sales_sum_cat4_med':'sum',\n",
    "    'is_sales_sum_vndr_top':'sum',\n",
    "    'is_sales_sum_vndr_hgh':'sum',\n",
    "#     'is_sales_sum_vndr_med':'sum',\n",
    "    'is_sales_cnt_top':'sum',\n",
    "    'is_sales_cnt_hgh':'sum',\n",
    "#     'is_sales_cnt_med':'sum',\n",
    "    'is_sales_cnt_cat2_top':'sum',\n",
    "    'is_sales_cnt_cat2_hgh':'sum',\n",
    "#     'is_sales_cnt_cat2_med':'sum',\n",
    "    'is_sales_cnt_cat3_top':'sum',\n",
    "    'is_sales_cnt_cat3_hgh':'sum',\n",
    "#     'is_sales_cnt_cat3_med':'sum',\n",
    "    'is_sales_cnt_cat4_top':'sum',\n",
    "    'is_sales_cnt_cat4_hgh':'sum',\n",
    "#     'is_sales_cnt_cat4_med':'sum',\n",
    "    'is_sales_cnt_vndr_top':'sum',\n",
    "    'is_sales_cnt_vndr_hgh':'sum',\n",
    "#     'is_sales_cnt_vndr_med':'sum',\n",
    "    'is_best_by_sum_plnt':'sum',\n",
    "    'is_best_by_sum_plid':'sum',\n",
    "    'is_best_by_sum_mtrl':'sum',\n",
    "    'is_best_by_sum_cat2':'sum',\n",
    "    'is_best_by_sum_cat3':'sum',\n",
    "    'is_best_by_sum_cat4':'sum',\n",
    "    'is_best_by_sum_vndr':'sum',\n",
    "    'is_best_by_cnt_plnt':'sum',\n",
    "    'is_best_by_cnt_plid':'sum',\n",
    "    'is_best_by_cnt_mtrl':'sum',\n",
    "    'is_best_by_cnt_cat2':'sum',\n",
    "    'is_best_by_cnt_cat3':'sum',\n",
    "    'is_best_by_cnt_cat4':'sum',\n",
    "    'is_best_by_cnt_vndr':'sum',\n",
    "    'is_price_discount':'sum',\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(result, how='left', on=['client_id', 'chq_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "result  = clients[['client_id',\n",
    "                         'best_by_sum_plnt',\n",
    "                         'best_by_sum_plid',\n",
    "                         'best_by_sum_mtrl',\n",
    "                         'best_by_sum_cat2',\n",
    "                         'best_by_sum_cat3',\n",
    "                         'best_by_sum_cat4',\n",
    "                         'best_by_sum_vndr',\n",
    "                         'best_by_cnt_plnt',\n",
    "                         'best_by_cnt_plid',\n",
    "                         'best_by_cnt_mtrl',\n",
    "                         'best_by_cnt_cat2',\n",
    "                         'best_by_cnt_cat3',\n",
    "                         'best_by_cnt_cat4',\n",
    "                         'best_by_cnt_vndr',\n",
    "                 ]]\n",
    "data = data.merge(result, how='left', on=['client_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Промежуточные датасеты далее не нужны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "del full\n",
    "del clients\n",
    "del materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={'chq_count_today':'chq_count', 'sum_today':'chq_sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "intcols = ['chq_count', 'transactions_count', 'is_promo',\n",
    "       'is_private_label', 'is_alco', 'is_type1_in_cat1', 'is_sales_sum_top',\n",
    "       'is_sales_sum_hgh', \n",
    "#            'is_sales_sum_med', \n",
    "           'is_sales_sum_cat2_top',\n",
    "       'is_sales_sum_cat2_hgh', \n",
    "#            'is_sales_sum_cat2_med',\n",
    "       'is_sales_sum_cat3_top', 'is_sales_sum_cat3_hgh',\n",
    "#        'is_sales_sum_cat3_med',\n",
    "           'is_sales_sum_cat4_top',\n",
    "       'is_sales_sum_cat4_hgh', \n",
    "#            'is_sales_sum_cat4_med',\n",
    "       'is_sales_sum_vndr_top', 'is_sales_sum_vndr_hgh',\n",
    "#        'is_sales_sum_vndr_med', \n",
    "           'is_sales_cnt_top', 'is_sales_cnt_hgh',\n",
    "#        'is_sales_cnt_med', \n",
    "           'is_sales_cnt_cat2_top', 'is_sales_cnt_cat2_hgh',\n",
    "#        'is_sales_cnt_cat2_med', \n",
    "           'is_sales_cnt_cat3_top',\n",
    "       'is_sales_cnt_cat3_hgh',\n",
    "#            'is_sales_cnt_cat3_med',\n",
    "       'is_sales_cnt_cat4_top', 'is_sales_cnt_cat4_hgh',\n",
    "#        'is_sales_cnt_cat4_med',\n",
    "           'is_sales_cnt_vndr_top',\n",
    "       'is_sales_cnt_vndr_hgh', \n",
    "#            'is_sales_cnt_vndr_med', \n",
    "           'is_best_by_sum_plnt',\n",
    "       'is_best_by_sum_plid', 'is_best_by_sum_mtrl', 'is_best_by_sum_cat2',\n",
    "       'is_best_by_sum_cat3', 'is_best_by_sum_cat4', 'is_best_by_sum_vndr',\n",
    "       'is_best_by_cnt_plnt', 'is_best_by_cnt_plid', 'is_best_by_cnt_mtrl',\n",
    "       'is_best_by_cnt_cat2', 'is_best_by_cnt_cat3', 'is_best_by_cnt_cat4',\n",
    "       'is_best_by_cnt_vndr', 'is_price_discount']\n",
    "reduce_to_int(data, intcols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### номер текущей недели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['week'] = data['chq_date'].dt.week.astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  rate_..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data.client_id==58].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_vars()\n",
    "def get_rolling_amount(grp, freq, col):\n",
    "    return grp.rolling(freq, on='chq_date')[col].sum()\n",
    "\n",
    "for col in ['chq_count', 'chq_sum', 'transactions_count']:  \n",
    "    data[f'{col}_1w'] = data.groupby('client_id', as_index=False, group_keys=False) \\\n",
    "                                .apply(get_rolling_amount, '7D', col)\n",
    "#     data[f'{col}_2w'] = data[f'{col}_1w'].shift(7)\n",
    "#     data[f'{col}_3w'] = data[f'{col}_2w'].shift(14)\n",
    "#     data[f'{col}_4w'] = data[f'{col}_3w'].shift(21)\n",
    "    data[f'{col}_1m'] = data.groupby('client_id', as_index=False, group_keys=False) \\\n",
    "                                .apply(get_rolling_amount, '31D', col)\n",
    "    data = data.fillna(0)\n",
    "    if col in ['chq_count', 'transactions_count']:\n",
    "        reduce_to_int(data, [f'{col}_1w', \n",
    "#                              f'{col}_2w', \n",
    "#                              f'{col}_3w', \n",
    "#                              f'{col}_4w', \n",
    "                             f'{col}_1m' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d3db4e30dd4d1198ab9149d338a1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=41.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['is_active', 'is_high_active', 'is_promo',\n",
    "       'is_private_label', 'is_alco', 'is_type1_in_cat1', 'is_sales_sum_top',\n",
    "       'is_sales_sum_hgh', \n",
    "#         'is_sales_sum_med', \n",
    "        'is_sales_sum_cat2_top',\n",
    "       'is_sales_sum_cat2_hgh', \n",
    "#         'is_sales_sum_cat2_med',\n",
    "       'is_sales_sum_cat3_top', 'is_sales_sum_cat3_hgh',\n",
    "#        'is_sales_sum_cat3_med', \n",
    "        'is_sales_sum_cat4_top',\n",
    "       'is_sales_sum_cat4_hgh', \n",
    "#         'is_sales_sum_cat4_med',\n",
    "       'is_sales_sum_vndr_top', 'is_sales_sum_vndr_hgh',\n",
    "#        'is_sales_sum_vndr_med',\n",
    "        'is_sales_cnt_top', 'is_sales_cnt_hgh',\n",
    "#        'is_sales_cnt_med', \n",
    "        'is_sales_cnt_cat2_top', 'is_sales_cnt_cat2_hgh',\n",
    "#        'is_sales_cnt_cat2_med', \n",
    "        'is_sales_cnt_cat3_top',\n",
    "       'is_sales_cnt_cat3_hgh',\n",
    "#         'is_sales_cnt_cat3_med',\n",
    "       'is_sales_cnt_cat4_top', 'is_sales_cnt_cat4_hgh',\n",
    "#        'is_sales_cnt_cat4_med', \n",
    "        'is_sales_cnt_vndr_top',\n",
    "       'is_sales_cnt_vndr_hgh', \n",
    "#         'is_sales_cnt_vndr_med',\n",
    "        'is_best_by_sum_plnt',\n",
    "       'is_best_by_sum_plid', 'is_best_by_sum_mtrl', 'is_best_by_sum_cat2',\n",
    "       'is_best_by_sum_cat3', 'is_best_by_sum_cat4', 'is_best_by_sum_vndr',\n",
    "       'is_best_by_cnt_plnt', 'is_best_by_cnt_plid', 'is_best_by_cnt_mtrl',\n",
    "       'is_best_by_cnt_cat2', 'is_best_by_cnt_cat3', 'is_best_by_cnt_cat4',\n",
    "       'is_best_by_cnt_vndr', 'is_price_discount']\n",
    "\n",
    "with tqdm(total=len(cols)) as pbar:\n",
    "    for col in cols:  \n",
    "        data[f'{col}_1w'] = data.groupby('client_id', as_index=False, group_keys=False) \\\n",
    "                                    .apply(get_rolling_amount, '7D', col)\n",
    "#         data[f'{col}_2w'] = data[f'{col}_1w'].shift(7)\n",
    "#         data[f'{col}_3w'] = data[f'{col}_2w'].shift(14)\n",
    "#         data[f'{col}_4w'] = data[f'{col}_3w'].shift(21)\n",
    "        data[f'{col}_1m'] = data.groupby('client_id', as_index=False, group_keys=False) \\\n",
    "                                    .apply(get_rolling_amount, '31D', col)\n",
    "\n",
    "#         data[f'rate_{col}'] = (data[col] / data['transactions_count']).astype(np.float32)\n",
    "#         data[f'rate_{col}_1w'] = (data[f'{col}_1w'] / data['transactions_count']).astype(np.float32)\n",
    "#         data[f'rate_{col}_2w'] = (data[f'{col}_2w'] / data['transactions_count']).astype(np.float32)\n",
    "#         data[f'rate_{col}_3w'] = (data[f'{col}_3w'] / data['transactions_count']).astype(np.float32)\n",
    "#         data[f'rate_{col}_4w'] = (data[f'{col}_4w'] / data['transactions_count']).astype(np.float32)\n",
    "#         data[f'rate_{col}_1m'] = (data[f'{col}_1m'] / data['transactions_count']).astype(np.float32)\n",
    "        \n",
    "#         data = data.drop(columns=[col, f'{col}_1w', f'{col}_2w', f'{col}_3w', f'{col}_4w', f'{col}_1m'])\n",
    "        data = data.fillna(0)\n",
    "        reduce_to_int(data, [f'{col}_1w', \n",
    "#                              f'{col}_2w', \n",
    "#                              f'{col}_3w', \n",
    "#                              f'{col}_4w', \n",
    "                             f'{col}_1m' ])\n",
    "        gc.collect()\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index(['client_id', 'chq_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Папка уже существует\n"
     ]
    }
   ],
   "source": [
    "path = str(workdir+'/data')\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "    print('Папка успешно создана!')\n",
    "else:\n",
    "    print('Папка уже существует')\n",
    "    \n",
    "data.to_pickle(path+'/data_done.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Проверка корреляции признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предполагалось выполнить проверку корреляции сформированных признаков. Однако, в связи с нехваткой времени и мощности аппаратных ресурсов, было принято решение пропустить этот этап. Также часть изначально задуманных признаков были закомментированы, чтобы уменьшить их количество и увеличить скорость дальнейших вычислений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Сохранение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним финальные данные в формате pickle для последующего использования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = str(workdir+'/data')\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "    print('Папка успешно создана!')\n",
    "else:\n",
    "    print('Папка уже существует')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(path+'/data_done.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = data.query(\"(chq_date != '2017-10-04') & (client_id < 5000)\").drop(columns='is_churn')\n",
    "# y_train = data.query(\"(chq_date != '2017-10-04') & (client_id < 5000)\")[['is_churn']]\n",
    "\n",
    "# X_test = data.query(\"chq_date == '2017-10-04'\").drop(columns='is_churn')\n",
    "# y_test = data.query(\"chq_date == '2017-10-04'\")[['is_churn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
